<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<head>
  <meta name=viewport content="width=800">
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
    /* Color scheme stolen from Sergey Karayev */
    
    a {
      color: #1772d0;
      text-decoration: none;
    }
    
    a:focus,
    a:hover {
      color: #f09228;
      text-decoration: none;
    }
    
    body,
    td,
    th,
    tr,
    p,
    a {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 16px
    }
    
    strong {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 16px;
    }
    
    heading {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 24px;
    }
    smallheading{
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 20px;
    }
    
    papertitle {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 16px;
      font-weight: 700
    }
    
    name {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 32px;
    }
    emal {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 16px;
    }
    
    .one {
      width: 160px;
      height: 160px;
      position: relative;
    }
    
    .two {
      width: 160px;
      height: 160px;
      position: absolute;
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }
    
    .fade {
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }

    span.highlight {
      background-color: #ffffd0;
    }
  </style>
  <link rel="icon" type="pics/png" href="main_pic.jpg">
  <title>Ivaxi Sheth</title>
  <meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
</head>

<body>
  <table width="800" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
      <td>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="67%" valign="middle">
              <p align="center">
                <name>Ivaxi Sheth</name>
              </p>
              <p align="center">
                <email align="center"> ivaxisheth17 at gmail dot com, ims116 at ic dot ac dot uk </email>
              </p>
              <p> I am currently AI Research Engineer at <a href="https://www.imaginationtech.com/vision-ai/img-series4-nna/ "> Imagination Technologies, UK </a>. I work mainly on 3D computer vision relating to video and medical images. From work, I have been inventors of two UK patents.
              </p>
              <p>
              I graduated with MEng Hons in Electrical and Electronic Engineering from Imperial College London. My areas of focus were Machine Learning and Computer Vision. 

              </p>
              <p align=center>
                <a href="mailto:ivaxisheth17@gmail.com">Email</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=Isz5M1UAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://twitter.com/ivakshi_s"> Twitter </a>  &nbsp/&nbsp
		<a href="https://www.linkedin.com/in/ivaxi-sheth-269454135"> Linkedin </a>     
              </p>
            </td>
            <td width="80%">
              <img src="main_pic.jpg" style="width:256px;height:400px" >
            </td>
          </tr>
        </table>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        	<tr>
            <td width="100%" valign="middle">
              <heading>News</heading>
              <p>
					    <ul>
						   
              <li> Stay tuned for ICCV paper results! :)
	      <li> Pre-print: <a href="https://openreview.net/forum?id=aAMgwCmP930">FHIST: A Benchmark for Few-shot Classification of Histological Images </a>This paper introduces a highly diversified public benchmark, gathered from various public datasets, for few-shot histology data classification. Our benchmark builds few-shot tasks and base-training data with various tissue types, different levels of domain shifts stemming from different cancer sites, and different class granularity levels, thereby reflecting realistic clinical settings. We evaluate the performances of state-of-the-art few-shot learning methods, initially designed for natural images, on our histology benchmark.
              <li> My paper <a href="https://arxiv.org/abs/2104.13051"> Three-stream network for enriched Action Recognition </a> was accepted at workshop at CVPR'21! - Three-stream network for enriched Action Recognition </li>
              <li> I submitted my thesis and graduated! </li>
					    </ul>
              </p>
            </td>
          </tr>
          <tr>

            <td width="100%" valign="middle">
              <heading>Research</heading>
              <p>
                My research interests include topics of computer vision - domain adaptation, temporal understanding, self-supervised learning. I am also interested in application of deep learning techniques on medical data. 
              </p>
            </td>
          </tr>
          <tr>
            <td width="100%" valign="middle">
              <heading>Publications</heading>
                <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                    <td valign="middle" width="70%">
                      <a href="https://openreview.net/forum?id=aAMgwCmP930">
                        <papertitle>FHIST: A Benchmark for Few-shot Classification of Histological Images</papertitle>
                      </a>
                      <br>
                      Fereshteh Shakeri,
                      Malik Boudiaf,
                      Sina Mohammadi,
                      <strong>Ivaxi Sheth</strong>, 
                      Mohammad Havaei,
                      Ismail Ben Ayed
                      Samira Ebrahimi Kahou.
                      <em>In submission</em>
                      <br>
                      Our benchmark builds few-shot tasks and base-training data with various tissue types, different levels of domain shifts stemming from different cancer sites, and different class granularity levels, thereby reflecting realistic clinical settings. We evaluate the performances of state-of-the-art few-shot learning methods, initially designed for natural images, on our histology benchmark.
                    </td>
                </table>
                <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                    <td valign="middle" width="70%">
                      <a href="https://arxiv.org/abs/2104.13051">
                        <papertitle>Three-stream network for enriched Action Recognition</papertitle>
                      </a>
                      <br>
                      <strong>Ivaxi Sheth</strong>, 
                      <em>CVPRW' 21</em>
                      <br>
                      We propose three stream network with each stream working on a different frame rate of input for action recognition and detection. We test our work on popular datasets such as Kinetics, UCF-101 and AVA. The results on AVA dataset particularly shows that effectiveness of the use of attention for each stream.
                    </td>
                </table>
            </td>
          </tr>
            <td width="100%" valign="middle">
              <heading>Patents</heading>
                <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                    <td valign="middle" width="70%">
                        <papertitle>Hardware implementation of windowed operations in three or more dimensions</papertitle>
                      </a>
                      <br>
                      <strong>Ivaxi Sheth</strong>, 
                      Cagatay Dickici,
                      Aria Ahamdi,
                      James Imber.
                      <em>In submission</em>
                      <br>
                    </td>
                </table>
                <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                    <td valign="middle" width="70%">
                        <papertitle>Hardware implementation of optimised winograd convolutions</papertitle>
                      </a>
                      <br>
                      James Imber,
                      Cagatay Dickici,
                      <strong>Ivaxi Sheth</strong>, 
                      <em>In submission</em>
                      <br>
                    </td>
                </table>
            </td>
        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td>
              <br>
              <p align="right">
                <font size="2">
			            This website is inspired by <a href="https://jonbarron.info/">Jon Barron</a>.
                </font>
              </p>
            </td>
          </tr>
        </table>
</body>

</html>
