<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<head>
  <meta name=viewport content="width=800">
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
    /* Color scheme stolen from Sergey Karayev */
    
    a {
      color: #1772d0;
      text-decoration: none;
    }
    
    a:focus,
    a:hover {
      color: #f09228;
      text-decoration: none;
    }
    
body, td, th, tr, p, a {
  font-family: 'Lato', Verdana, Helvetica, sans-serif;
  font-size: 15px; /* Reduced font size */
}

papertitle {
    font-size: 16px;
    font-weight: bold; /* This will make the text bold */
}
	  
strong {
    font-weight: normal; /* Removes the bold effect */
    text-decoration: underline; /* Adds underline */
}

    
emal {
  font-size: 15px; /* Consistent reduction */
}

heading {
  font-size: 22px; /* Slightly reduced */
}

smallheading {
  font-size: 18px; /* Slightly reduced */
}

name {
  font-size: 28px; /* Reduced size for name */
}
    emal {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 16px;
    }
    
    .one {
      width: 160px;
      height: 160px;
      position: relative;
    }
    
    .two {
      width: 160px;
      height: 160px;
      position: absolute;
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }
    
    .fade {
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }

    span.highlight {
      background-color: #ffffd0;
    }
  </style>
<td width="90%" valign="middle">
  <link rel="icon" type="pics/png" href="Headshot.jpeg">
  <title>Ivaxi Sheth</title>
  <meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
</head>

<body>
  <table width="800" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
      <td>
	<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
              <p align="center">
                <name>Ivaxi Sheth</name>
              </p>
<img src="Headshot.jpeg" style="float: right; margin-left: 15px; margin-bottom: 15px; width: 200px; height: 200px;">

<p>I am a PhD student at <a href="https://cispa.de/en">CISPA Helmholtz Center</a> under the supervision of <a href="https://cispa.saarland/group/fritz/">Prof. Mario Fritz</a>. My research focuses on the dual use of Large Language Models (LLMs), covering the following key areas:</p>

	
<ul>
  <li>
    <papertitle>LLMs for Scientific Discovery</papertitle><br>
    I am exploring how LLMs can assist in accelerating scientific discovery, particularly in hypothesis generation and causal reasoning.<br>
    See <a href="#hypothesizing-causal-variables">this </a> and <a href="#causalgraph2llm">this. </a>
  </li>
  <li>
    <papertitle>LLMs Safety, Control and Interpretability</papertitle><br>
    My research also investigates how LLMs can be made more trustworthy by focusing on safety, representation control, improving interpretability for practical applications, ethics and biases.<br>
    See <a href="#causalgraph2llm">this</a>, <a href="#task-switch">this,</a> and <a href="#ethics">this.</a> 
  </li>
 <li>
    <papertitle>Human-AI Interaction </papertitle><br>
    I am also interested in ensuring effective human oversight over models, particularly necessary for scientific discovery and decision-making processes. This is key to maintaining human autonomy, as LLMs become more embedded in research and applications.<br>
    See <a href="#cbmneurips"> this</a> and <a href="#intervention"> this.</a>
  </li>

</ul>
    
              </p>
              <p>
              I graduated with BEng + MEng Hons in <a href="https://www.imperial.ac.uk/electrical-engineering/">Electrical and Electronic Engineering</a> from <a href="https://www.imperial.ac.uk/">Imperial College London</a>. My areas of focus were Machine Learning and Computer Vision supervised by <a href="https://cciliber.github.io/">Dr. Carlo Ciliberto</a>. Previously I was a research assistant at <a href="https://mila.quebec/en/">Mila-Quebec AI</a>.  I also worked as an AI Research Engineer at <a href="https://www.imaginationtech.com/vision-ai/img-series4-nna/ "> Imagination Technologies, UK </a> under <a href="https://scholar.google.com/citations?hl=en&user=x_zcKisAAAAJ&view_op=list_works">Dr. Cagatay Dikici</a> working on the Hardware Acceleration of neural networks.
              </p>

		<p>
 		 Outside of research, I love dancing and hold a diploma in Kathak. I actively mentor and perform Kathak, having performed across multiple cities in six countries.
		</p>
	      <p>
		If you are working on a similar topic or are interested in collaborating, I would love to hear from you!
              </p>
              <p align=center>
                <a href="mailto:ivaxisheth17@gmail.com">Email</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=Isz5M1UAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://twitter.com/ivakshi_s"> Twitter </a>  &nbsp/&nbsp
		<a href="https://www.linkedin.com/in/ivaxi-sheth-269454135"> Linkedin </a>     
              </p>
            </td>
            <td width="80%">
            </td>
          </tr>
        </table>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        	<tr>
            <td width="100%" valign="middle">
              <heading>News (not always updated) </heading>
              <p>
					    <ul>
		<li> Two new preprints - <a href="https://arxiv.org/abs/2410.15939">CausalGraph2LLM: Evaluating LLMs for Causal Queries</a> and <a href="https://arxiv.org/abs/2410.15828">LLM4GRN: Discovering Causal Gene Regulatory Networks with LLMs -- Evaluation through Synthetic Data Generation</a> </li>
	      <li> Our paper <a href="https://arxiv.org/abs/2402.18216"> LLM Task Interference: An Initial Study on the Impact of Task-Switch in Conversational History</a> is accepted at EMNLP 2024, see you in Miami.</li>
	       <li> New paper preprint - <a href="https://arxiv.org/pdf/2409.02604"> Hypothesizing Missing Causal Variables </li>				    
	      <li> Our paper <a href="https://arxiv.org/abs/2310.10702">Transparent Anomaly Detection via Concept-based Explanations</a> got accepted at <a href="https://xai-in-action.github.io/"> XAI in Action workshop</a> at Neurips 2023. 
	      <li> Our paper <a href="https://openreview.net/forum?id=jvYXln6Gzn"> Auxiliary Losses for Learning Generalizable Concept-based Models </a> got accepted at <b>Neurips 2023</b>. See you in New Orleans!
        <li> Our paper <a href="https://link.springer.com/chapter/10.1007/978-3-031-45673-2_32"> RelationalUNet for Image Segmentation </a> got accepted at MLMI. 
					    </ul>
              </p>
            </td>
          </tr>
          <tr>
          </tr>

	  
          <tr>
            <td width="100%" valign="middle">
              <heading>Publications</heading>
              <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()">
                  <td style="padding:20px;width:25%;vertical-align:middle">
                    <img src="pics/hypothesizingcausal.png" alt="elign" style="border-style: none" width="200">
                  </td>
                  <td style="padding:20px;width:75%;vertical-align:middle">
		    <a name="hypothesizing-causal-variables"></a>

                      <papertitle>Hypothesizing Missing Causal Variables</papertitle>
                    <br>
                    <strong>Ivaxi Sheth</strong>,
                    <a href="https://s-abdelnabi.github.io/">Sahar Abdelnabi</a>,
	            <a href="https://cispa.saarland/group/fritz/">Mario Fritz</a>.
                    <br>
                    <em> Preprint & CALM Neurips'24 Workshop </em> 
                    <br>
                    [
                    <a href="https://arxiv.org/pdf/2409.02604">Paper</a>, <a href="https://github.com/ivaxi0s/hypothesizing-causal-variable-llm">Code</a>
                     ]
                    <br>
                    <p>
                      Can LLMs fill in the gaps of scientific discovery? This work challenges Large Language Models to complete partial causal graphs, revealing their surprising strengths—and limitations—in hypothesizing missing variables.
                  </td>
                </tr>

		      
                <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()">
                  <td style="padding:20px;width:25%;vertical-align:middle">
                    <img src="pics/causalg2llm.png" alt="elign" style="border-style: none" width="250">
                  </td>
                  <td style="padding:20px;width:75%;vertical-align:middle">
		    <a name="causalgraph2llm"></a>
		<papertitle>CausalGraph2LLM: Evaluating LLMs for Causal Queries</papertitle>
                    <br>
                    <strong>Ivaxi Sheth</strong>,
                    <a href="https://baharefatemi.github.io/homepage/">Bahare Fatemi</a>,
	            <a href="https://cispa.saarland/group/fritz/">Mario Fritz</a>.
                    <br>
                    <em> Preprint & CALM Neurips'24 Workshop </em> 
                    <br>
                    [
                    <a href="https://arxiv.org/abs/2410.15939">Paper</a>, <a href="https://github.com/ivaxi0s/CausalGraph2LLM">Code</a>
                     ]
                    <br>
                    <p>
                      This paper introduces CausalGraph2LLM, the first comprehensive benchmark to evaluate Large Language Models' ability to understand and reason with causal graphs, revealing their sensitivity to encoding and potential biases in downstream tasks.
                </tr>

                <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()">
                  <td style="padding:20px;width:25%;vertical-align:middle">
                    <img src="pics/llm4grn.png" alt="elign" style="border-style: none" width="250">
                  </td>
                  <td style="padding:20px;width:75%;vertical-align:middle">
		    <a name="llm4grn"></a>
		<papertitle>LLM4GRN: Discovering Causal Gene Regulatory Networks with LLMs -- Evaluation through Synthetic Data Generation</papertitle>
                    <be>
		   <a href="https://tejuafonja.com/">Tejumade Afonja*</a>,
                    <strong>Ivaxi Sheth*</strong>,
                    <a href="https://www.rutabinkyte.com/">Ruta Binkyte*</a>,
	             Waqar Hanif, Thomas Ulas, Matthias Becker, 
	            <a href="https://cispa.saarland/group/fritz/">Mario Fritz</a>.
                    <br>
                    <em> Preprint </em> 
                    <br>
                    [
                    <a href="https://arxiv.org/abs/2410.15828#">Paper</a>, <a href="">Code</a>
                     ]
                    <br>
                    <p>
                     This paper explores the use of large language models (LLMs) for discovering gene regulatory networks (GRNs) from single-cell RNA sequencing data, demonstrating their effectiveness in guiding causal data generation and enhancing statistical modeling in biological research.                </tr>		      

		      
                <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()">
                  <td style="padding:20px;width:25%;vertical-align:middle">
                    <img src="pics/task-switch.png" alt="elign" style="border-style: none" width="250">
                  </td>
                  <td style="padding:20px;width:75%;vertical-align:middle">
		<a name="task-switch"></a>
                      <papertitle>LLM Task Interference: An Initial Study on the Impact of Task-Switch in Conversational History</papertitle>
                    <br>
	            <a href="https://scholar.google.com/citations?user=6Ngx1n8AAAAJ&hl=en&oi=sra">Akash Gupta*</a>,
                    <strong>Ivaxi Sheth*</strong>,
	            <a href="https://scholar.google.com/citations?user=BxFBCoYAAAAJ&hl=en">Vyas Raina*</a>,
                    <a href="https://mi.eng.cam.ac.uk/~mjfg/index.html">Mark Gales</a>,
	            <a href="https://cispa.saarland/group/fritz/">Mario Fritz</a>.
                    <br>
                    <em> EMNLP Main 2024 </em> 
			  <p> </p>
		   <em> ICML Foundation Models in Wild Workshop 2024</em>
                    <br>
                    [
                    <a href="https://arxiv.org/abs/2402.18216">Paper</a>, <a href="https://github.com/ivaxi0s/llm-task-switch">Code</a>
                     ]
                    <br>
                    <p>
                      Large Language Models (LLMs) can perform a wide range of tasks, but their performance can be negatively impacted when there's a switch in tasks. This study is the first to formalize the study of such vulnerabilities, revealing that both very large and small LLMs can be susceptible to performance degradation from task-switches.
                  </td>
                </tr>
		      
                <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()">
                  <td style="padding:20px;width:25%;vertical-align:middle">
                    <img src="pics/coopcbm.png" alt="elign" style="border-style: none" width="250">
                  </td>
                  <td style="padding:20px;width:75%;vertical-align:middle">
		<a name="cbmneurips"></a>
		<papertitle>Auxiliary Losses for Learning Generalizable Concept-based Models</papertitle>
                    <br>
                    <strong>Ivaxi Sheth</strong>,
                    <a href="https://saebrahimi.github.io/">Samira Ebrahimi Kahou</a>
                    <br>
                    <em> NeurIPS 2023 </em> 
                    <br>
                    [
                    <a href="https://openreview.net/pdf?id=jvYXln6Gzn">Paper</a>, <a href="https://github.com/ivaxi0s/coop-cbm">Code</a>
                     ]
                    <br>
                    <p>
                      We proposed a multi-task learning paradigm for Concept Bottleneck Models to introduce inductive bias in concept learning. Our proposed model coop-CBM improves the downstream task accuracy over black box standard models. Using the concept orthogonal loss, we introduce orthogonality among concepts in the training of CBMs.
                  </td>
                </tr>


                <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()">
                  <td style="padding:20px;width:25%;vertical-align:middle">
                    <img src="pics/ACE-firstpage2.png" alt="elign" style="border-style: none" width="250">
                  </td>
                  <td style="padding:20px;width:75%;vertical-align:middle">
                      <papertitle>Transparent Anomaly Detection via Concept-based Explanations</papertitle>
                    <br>
                    <a href="https://scholar.google.ca/citations?user=-hIQXcQAAAAJ&hl=en">Laya Rafiee Sevyeri*</a>
                    <strong>Ivaxi Sheth*</strong>,
                    <a href="https://scholar.google.com/citations?user=Zv-gelkAAAAJ&hl=en">Farhood Farahnak*</a>
                    <a href="https://saebrahimi.github.io/">Samira Ebrahimi Kahou</a>
                    <a href="https://www.mcgill.ca/bbme/shirin-abbasi-nejad-enger">Shirin Abbasinejad Enger</a>
                    <br>
                    <em>NeurIPS 2023, XAI in Action </em> 
                    <br>
                    [
                    <a href="https://arxiv.org/abs/2310.10702">Paper</a>
                     ]
                    <br>
                    <p>
                      We propose Transparent {A}nomaly Detection {C}oncept {E}xplanations (ACE). ACE is able to provide human interpretable explanations in the form of concepts along with anomaly prediction. Our proposed model shows either higher or comparable results to black-box uninterpretable models.
                  </td>
                </tr>                
		                
		<tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()">
                  <td style="padding:20px;width:25%;vertical-align:middle">
                    <img src="pics/causalg2llm.png" alt="elign" style="border-style: none" width="250">
                  </td>
                  <td style="padding:20px;width:75%;vertical-align:middle">
		    <a name="ethics"></a>
		<papertitle>Survey on AI Ethics: A Socio-technical Perspective</papertitle>
                    <br>
                    Dave Mbiazi*, Meghana Bhange*, Maryam Babaei*,<strong> Ivaxi Sheth*</strong>, Patrik Joslin Kenfack*,
                    <br>
                    <em> Preprint </em> 
                    <br>
                    [
                    <a href="https://arxiv.org/abs/2311.17228">Paper</a>
                     ]
                    <br>
                    <p>
			This work unifies the current and future ethical concerns of deploying AI into society.
		</tr>

                <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()">
                  <td style="padding:20px;width:25%;vertical-align:middle">
                    <img src="pics/runet.png" alt="elign" style="border-style: none" width="250">
                  </td>
                  <td style="padding:20px;width:75%;vertical-align:middle">
                      <papertitle>Relational UNet for Image Segmentation</papertitle>
                    <br>
                    <strong>Ivaxi Sheth*</strong>,
                    <a href="">Pedro Braga*</a>,
                    <a href="https://shivakanthsujit.github.io/">Shivakanth Sujit*</a>,
                    Sahar Dastani,
                    <a href="https://saebrahimi.github.io/">Samira Ebrahimi Kahou</a>
                    <br>
                    <em> International Workshop on Machine Learning in Medical Imaging 2023 </em> 
                    <br>
                    [
                    <a href="https://arxiv.org/abs/2310.10702">Paper</a> , <a href="https://github.com/ivaxi0s/runet">Code</a>
                     ]
                    <br>
                    <p>
                      We propose RelationalUNet which introduces relational feature transformation to the UNet architecture. RelationalUNet models the dynamics between visual and depth dimensions of a 3D medical image by introducing Relational Self-Attention blocks in skip connections.                    </td>
                </tr> 
                


                <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()">
                  <td style="padding:20px;width:25%;vertical-align:middle">
                    <img src="pics/siul.png" alt="elign" style="border-style: none" width="250">
                  </td>
                  <td style="padding:20px;width:75%;vertical-align:middle">
		<a name="intervention"></a>
                      <papertitle>Learning from uncertain concepts via test time interventions</papertitle>
                    <br>
                    <strong>Ivaxi Sheth</strong>,
                    <a href="https://aamer98.github.io/">Aamer Abdul Rahman</a>,
                    <a href="https://scholar.google.ca/citations?user=-hIQXcQAAAAJ&hl=en">Laya Rafiee Sevyeri</a>,
                    <a href="https://scholar.google.com/citations?user=LAoMyyoAAAAJ&hl=en">Mohammad Havaei<a>
                    <a href="https://saebrahimi.github.io/">Samira Ebrahimi Kahou</a>
                    <br>
                    <em> NeurIPS 2022, Trustworthy and Socially Responsible Machine Learning Workshop                    </em> 
                    <br>
                    [
                    <a href="https://openreview.net/pdf?id=WVe3vok8Cc3">Paper</a> 
                     ]
                    <br>
                    <p>
                      We propose uncertainty based strategy to select the interventions in Concept Bottleneck Models during inference. 
                    </td>
                </tr> 

                
                <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                    <td valign="middle" width="70%">
                      <a href="https://openreview.net/forum?id=aAMgwCmP930">
                        <papertitle>FHIST: A Benchmark for Few-shot Classification of Histological Images</papertitle>
                      </a>
                      <br>
                      Fereshteh Shakeri,
                      Malik Boudiaf,
                      Sina Mohammadi,
                      <strong>Ivaxi Sheth</strong>, 
                      Mohammad Havaei,
                      Ismail Ben Ayed
                      Samira Ebrahimi Kahou.
                      <em>In submission</em>
                      <br>
                      Our benchmark builds few-shot tasks and base-training data with various tissue types, different levels of domain shifts stemming from different cancer sites, and different class granularity levels, thereby reflecting realistic clinical settings. We evaluate the performances of state-of-the-art few-shot learning methods, initially designed for natural images, on our histology benchmark.
                    </td>
                </table>
                <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                    <td valign="middle" width="70%">
                      <a href="https://arxiv.org/abs/2104.13051">
                        <papertitle>Three-stream network for enriched Action Recognition</papertitle>
                      </a>
                      <br>
                      <strong>Ivaxi Sheth</strong>, 
                      <em>CVPRW' 21</em>
                      <br>
                      We propose three stream network with each stream working on a different frame rate of input for action recognition and detection. We test our work on popular datasets such as Kinetics, UCF-101 and AVA. The results on AVA dataset particularly shows that effectiveness of the use of attention for each stream.
                    </td>
                </table>
            </td>
          </tr>
            <td width="100%" valign="middle">
              <heading>Patents</heading>
                <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                    <td valign="middle" width="70%">
                        <papertitle>Hardware implementation of windowed operations in three or more dimensions</papertitle>
                      </a>
                      <br>
                      <strong>Ivaxi Sheth</strong>, 
                      Cagatay Dickici,
                      Aria Ahamdi,
                      James Imber.
                      <em>In submission</em>
                      <br>
                    </td>
                </table>
            </td>
        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td>
              <br>
              <p align="right">
                <font size="2">
			            This website template - <a href="https://jonbarron.info/">Jon Barron</a>.
                </font>
              </p>
            </td>
          </tr>
        </table>
</body>

</html>
