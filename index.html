<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<head>
  <meta name=viewport content="width=800">
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
    /* Color scheme stolen from Sergey Karayev */
    
    a {
      color: #1772d0;
      text-decoration: none;
    }
    
    a:focus,
    a:hover {
      color: #f09228;
      text-decoration: none;
    }
    
    body,
    td,
    th,
    tr,
    p,
    a {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 16px
    }
    
    strong {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 16px;
    }
    
    heading {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 24px;
    }
    smallheading{
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 20px;
    }
    
    papertitle {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 16px;
      font-weight: 700
    }
    
    name {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 32px;
    }
    emal {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 16px;
    }
    
    .one {
      width: 160px;
      height: 160px;
      position: relative;
    }
    
    .two {
      width: 160px;
      height: 160px;
      position: absolute;
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }
    
    .fade {
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }

    span.highlight {
      background-color: #ffffd0;
    }
  </style>
  <link rel="icon" type="pics/png" href="Headshot.jpeg">
  <title>Ivaxi Sheth</title>
  <meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
</head>

<body>
  <table width="800" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
      <td>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="67%" valign="middle">
              <p align="center">
                <name>Ivaxi Sheth</name>
              </p>

              <p> I am a PhD student at <a href="https://cispa.de/en">CISPA Helmholtz Center for Information Security</a> under supervision of <a href="https://cispa.saarland/group/fritz/">Prof. Mario Fritz</a>. My current research interests fall under the broad section of Trustworthy Machine Learning, particularly generalization and explainability. I am currently exploring the intersection of causality and language models.
              </p>
              <p>
              Previously I was at <a href="https://mila.quebec/en/">Mila-Quebec AI</a>. I graduated with MEng Hons in Electrical and Electronic Engineering from Imperial College London. My areas of focus were Machine Learning and Computer Vision supervised by <a href="https://cciliber.github.io/">Dr. Carlo Ciliberto</a>. Previously I worked as an AI Research Engineer at <a href="https://www.imaginationtech.com/vision-ai/img-series4-nna/ "> Imagination Technologies, UK </a> under <a href="https://scholar.google.com/citations?hl=en&user=x_zcKisAAAAJ&view_op=list_works">Dr. Cagatay Dikici</a> working on Hardware Acceleration of neural networks.
              </p>
              <p align=center>
                <a href="mailto:ivaxisheth17@gmail.com">Email</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=Isz5M1UAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://twitter.com/ivakshi_s"> Twitter </a>  &nbsp/&nbsp
		<a href="https://www.linkedin.com/in/ivaxi-sheth-269454135"> Linkedin </a>     
              </p>
            </td>
            <td width="80%">
              <img src="Headshot.jpeg" style="width:256px;height:256px" >
            </td>
          </tr>
        </table>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        	<tr>
            <td width="100%" valign="middle">
              <heading>News</heading>
              <p>
					    <ul>
	      <li> Checkout our new pre-print <a href="https://arxiv.org/abs/2402.18216"> LLM Task Interference: An Initial Study on the Impact of Task-Switch in Conversational History. </li>
	      <li> Our paper <a href="https://arxiv.org/abs/2310.10702">Transparent Anomaly Detection via Concept-based Explanations</a> got accepted at <a href="https://xai-in-action.github.io/"> XAI in Action workshop</a> at Neurips 2023. 
	      <li> Our paper <a href="https://openreview.net/forum?id=jvYXln6Gzn"> Auxiliary Losses for Learning Generalizable Concept-based Models </a> got accepted at <b>Neurips 2023</b>. See you in New Orleans!
        <li> Our paper <a href="https://link.springer.com/chapter/10.1007/978-3-031-45673-2_32"> RelationalUNet for Image Segmentation </a> got accepted at MLMI. 
					    </ul>
              </p>
            </td>
          </tr>
          <tr>
          </tr>
          <tr>
            <td width="100%" valign="middle">
              <heading>Publications</heading>
              <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


                <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()">
                  <td style="padding:20px;width:25%;vertical-align:middle">
                    <img src="pics/task-switch.png" alt="elign" style="border-style: none" width="350">
                  </td>
                  <td style="padding:20px;width:75%;vertical-align:middle">
                    <a href="">
                      <papertitle>LLM Task Interference: An Initial Study on the Impact of Task-Switch in Conversational History</papertitle>
                    </a>
                    <br>
	            <a href="https://scholar.google.com/citations?user=6Ngx1n8AAAAJ&hl=en&oi=sra">Akash Gupta</a>,
                    <strong>Ivaxi Sheth</strong>,
	            <a href="https://scholar.google.com/citations?user=BxFBCoYAAAAJ&hl=en">Vyas Raina</a>,
                    <a href="https://mi.eng.cam.ac.uk/~mjfg/index.html">Mark Gales</a>,
	            <a href="https://cispa.saarland/group/fritz/">Mario Fritz</a>.
                    <br>
                    <em> Preprint </em> 
                    <br>
                    [
                    <a href="https://arxiv.org/abs/2402.18216">Paper</a>, <a href="https://github.com/ivaxi0s/llm-task-switch">Code</a>
                     ]
                    <br>
                    <p>
                      Large Language Models (LLMs) can perform a wide range of tasks, but their performance can be negatively impacted when there's a switch in tasks. This study is the first to formalize the study of such vulnerabilities, revealing that both very large and small LLMs can be susceptible to performance degradation from task-switches.
                  </td>
                </tr>
		      
                <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()">
                  <td style="padding:20px;width:25%;vertical-align:middle">
                    <img src="pics/coopcbm.png" alt="elign" style="border-style: none" width="350">
                  </td>
                  <td style="padding:20px;width:75%;vertical-align:middle">
                    <a href="">
                      <papertitle>Auxiliary Losses for Learning Generalizable Concept-based Models</papertitle>
                    </a>
                    <br>
                    <strong>Ivaxi Sheth</strong>,
                    <a href="https://saebrahimi.github.io/">Samira Ebrahimi Kahou</a>
                    <br>
                    <em> NeurIPS 2023 </em> 
                    <br>
                    [
                    <a href="https://openreview.net/pdf?id=jvYXln6Gzn">Paper</a>, <a href="https://github.com/ivaxi0s/coop-cbm">Code</a>
                     ]
                    <br>
                    <p>
                      We proposed a multi-task learning paradigm for Concept Bottleneck Models to introduce inductive bias in concept learning. Our proposed model coop-CBM improves the downstream task accuracy over black box standard models. Using the concept orthogonal loss, we introduce orthogonality among concepts in the training of CBMs.
                  </td>
                </tr>


                <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()">
                  <td style="padding:20px;width:25%;vertical-align:middle">
                    <img src="pics/ACE-firstpage2.png" alt="elign" style="border-style: none" width="350">
                  </td>
                  <td style="padding:20px;width:75%;vertical-align:middle">
                    <a href="">
                      <papertitle>Transparent Anomaly Detection via Concept-based Explanations</papertitle>
                    </a>
                    <br>
                    <a href="https://scholar.google.ca/citations?user=-hIQXcQAAAAJ&hl=en">Laya Rafiee Sevyeri*</a>
                    <strong>Ivaxi Sheth*</strong>,
                    <a href="https://scholar.google.com/citations?user=Zv-gelkAAAAJ&hl=en">Farhood Farahnak*</a>
                    <a href="https://saebrahimi.github.io/">Samira Ebrahimi Kahou</a>
                    <a href="https://www.mcgill.ca/bbme/shirin-abbasi-nejad-enger">Shirin Abbasinejad Enger</a>
                    <br>
                    <em>NeurIPS 2023, XAI in Action </em> 
                    <br>
                    [
                    <a href="https://arxiv.org/abs/2310.10702">Paper</a>
                     ]
                    <br>
                    <p>
                      We propose Transparent {A}nomaly Detection {C}oncept {E}xplanations (ACE). ACE is able to provide human interpretable explanations in the form of concepts along with anomaly prediction. Our proposed model shows either higher or comparable results to black-box uninterpretable models.
                  </td>
                </tr>                


                <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()">
                  <td style="padding:20px;width:25%;vertical-align:middle">
                    <img src="pics/runet.png" alt="elign" style="border-style: none" width="350">
                  </td>
                  <td style="padding:20px;width:75%;vertical-align:middle">
                    <a href="">
                      <papertitle>Relational UNet for Image Segmentation</papertitle>
                    </a>
                    <br>
                    <strong>Ivaxi Sheth*</strong>,
                    <a href="">Pedro Braga*</a>,
                    <a href="https://shivakanthsujit.github.io/">Shivakanth Sujit*</a>,
                    Sahar Dastani,
                    <a href="https://saebrahimi.github.io/">Samira Ebrahimi Kahou</a>
                    <br>
                    <em> International Workshop on Machine Learning in Medical Imaging 2023 </em> 
                    <br>
                    [
                    <a href="https://arxiv.org/abs/2310.10702">Paper</a> , <a href="https://github.com/ivaxi0s/runet">Code</a>
                     ]
                    <br>
                    <p>
                      We propose RelationalUNet which introduces relational feature transformation to the UNet architecture. RelationalUNet models the dynamics between visual and depth dimensions of a 3D medical image by introducing Relational Self-Attention blocks in skip connections.                    </td>
                </tr> 
                


                <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()">
                  <td style="padding:20px;width:25%;vertical-align:middle">
                    <img src="pics/siul.png" alt="elign" style="border-style: none" width="350">
                  </td>
                  <td style="padding:20px;width:75%;vertical-align:middle">
                    <a href="">
                      <papertitle>Learning from uncertain concepts via test time interventions</papertitle>
                    </a>
                    <br>
                    <strong>Ivaxi Sheth</strong>,
                    <a href="https://aamer98.github.io/">Aamer Abdul Rahman</a>,
                    <a href="https://scholar.google.ca/citations?user=-hIQXcQAAAAJ&hl=en">Laya Rafiee Sevyeri</a>,
                    <a href="https://scholar.google.com/citations?user=LAoMyyoAAAAJ&hl=en">Mohammad Havaei<a>
                    <a href="https://saebrahimi.github.io/">Samira Ebrahimi Kahou</a>
                    <br>
                    <em> NeurIPS 2022, Trustworthy and Socially Responsible Machine Learning Workshop                    </em> 
                    <br>
                    [
                    <a href="https://openreview.net/pdf?id=WVe3vok8Cc3">Paper</a> 
                     ]
                    <br>
                    <p>
                      We propose uncertainty based strategy to select the interventions in Concept Bottleneck Models during inference. 
                    </td>
                </tr> 

                
                <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                    <td valign="middle" width="70%">
                      <a href="https://openreview.net/forum?id=aAMgwCmP930">
                        <papertitle>FHIST: A Benchmark for Few-shot Classification of Histological Images</papertitle>
                      </a>
                      <br>
                      Fereshteh Shakeri,
                      Malik Boudiaf,
                      Sina Mohammadi,
                      <strong>Ivaxi Sheth</strong>, 
                      Mohammad Havaei,
                      Ismail Ben Ayed
                      Samira Ebrahimi Kahou.
                      <em>In submission</em>
                      <br>
                      Our benchmark builds few-shot tasks and base-training data with various tissue types, different levels of domain shifts stemming from different cancer sites, and different class granularity levels, thereby reflecting realistic clinical settings. We evaluate the performances of state-of-the-art few-shot learning methods, initially designed for natural images, on our histology benchmark.
                    </td>
                </table>
                <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                    <td valign="middle" width="70%">
                      <a href="https://arxiv.org/abs/2104.13051">
                        <papertitle>Three-stream network for enriched Action Recognition</papertitle>
                      </a>
                      <br>
                      <strong>Ivaxi Sheth</strong>, 
                      <em>CVPRW' 21</em>
                      <br>
                      We propose three stream network with each stream working on a different frame rate of input for action recognition and detection. We test our work on popular datasets such as Kinetics, UCF-101 and AVA. The results on AVA dataset particularly shows that effectiveness of the use of attention for each stream.
                    </td>
                </table>
            </td>
          </tr>
            <td width="100%" valign="middle">
              <heading>Patents</heading>
                <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                    <td valign="middle" width="70%">
                        <papertitle>Hardware implementation of windowed operations in three or more dimensions</papertitle>
                      </a>
                      <br>
                      <strong>Ivaxi Sheth</strong>, 
                      Cagatay Dickici,
                      Aria Ahamdi,
                      James Imber.
                      <em>In submission</em>
                      <br>
                    </td>
                </table>
            </td>
        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td>
              <br>
              <p align="right">
                <font size="2">
			            This website template - <a href="https://jonbarron.info/">Jon Barron</a>.
                </font>
              </p>
            </td>
          </tr>
        </table>
</body>

</html>
